{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS backend is available.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    print(\"MPS backend is available.\")\n",
    "else:\n",
    "    print(\"MPS backend is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-23T05:39:53.755042Z",
     "iopub.status.busy": "2025-04-23T05:39:53.754737Z",
     "iopub.status.idle": "2025-04-23T05:39:53.760480Z",
     "shell.execute_reply": "2025-04-23T05:39:53.759428Z",
     "shell.execute_reply.started": "2025-04-23T05:39:53.755020Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/diana/Documents/GitHub/Hates-speech-detection/notebooks\n"
     ]
    }
   ],
   "source": [
    "%cd Documents/GitHub/Hates-speech-detection/notebooks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/diana\n"
     ]
    }
   ],
   "source": [
    "%cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T05:39:56.545384Z",
     "iopub.status.busy": "2025-04-23T05:39:56.544963Z",
     "iopub.status.idle": "2025-04-23T05:40:27.709433Z",
     "shell.execute_reply": "2025-04-23T05:40:27.708444Z",
     "shell.execute_reply.started": "2025-04-23T05:39:56.545349Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)  \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "df = load_data('../embeddings/fast_russian_embeddings.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T17:07:03.284039Z",
     "iopub.status.busy": "2025-04-22T17:07:03.283683Z",
     "iopub.status.idle": "2025-04-22T17:07:03.316900Z",
     "shell.execute_reply": "2025-04-22T17:07:03.316035Z",
     "shell.execute_reply.started": "2025-04-22T17:07:03.284017Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>252099-79.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.012139108963310719, 0.02229919657111168, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842673-37.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.027081843465566635, 0.023928195238113403, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>843784-82.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.01613425277173519, 0.025259848684072495, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>521607-8.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.03023727424442768, -0.0032445243559777737,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>406175-82.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.021884415298700333, 0.014899949543178082, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        filename  label                                          embedding\n",
       "0  252099-79.txt      0  [-0.012139108963310719, 0.02229919657111168, 0...\n",
       "1  842673-37.txt      0  [-0.027081843465566635, 0.023928195238113403, ...\n",
       "2  843784-82.txt      0  [0.01613425277173519, 0.025259848684072495, -0...\n",
       "3   521607-8.txt      0  [-0.03023727424442768, -0.0032445243559777737,...\n",
       "4  406175-82.txt      0  [0.021884415298700333, 0.014899949543178082, 0..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T05:40:49.505613Z",
     "iopub.status.busy": "2025-04-23T05:40:49.505242Z",
     "iopub.status.idle": "2025-04-23T05:40:52.390619Z",
     "shell.execute_reply": "2025-04-23T05:40:52.389601Z",
     "shell.execute_reply.started": "2025-04-23T05:40:49.505581Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "df['label_encoded'] = le.fit_transform(df['label'])\n",
    "X = np.array(df['embedding'].tolist())\n",
    "y = df['label_encoded'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T05:40:52.392548Z",
     "iopub.status.busy": "2025-04-23T05:40:52.392197Z",
     "iopub.status.idle": "2025-04-23T05:40:52.581937Z",
     "shell.execute_reply": "2025-04-23T05:40:52.580762Z",
     "shell.execute_reply.started": "2025-04-23T05:40:52.392522Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T17:07:38.696415Z",
     "iopub.status.busy": "2025-04-22T17:07:38.696063Z",
     "iopub.status.idle": "2025-04-22T17:08:28.632759Z",
     "shell.execute_reply": "2025-04-22T17:08:28.631814Z",
     "shell.execute_reply.started": "2025-04-22T17:07:38.696387Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Test Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.55      0.58      2921\n",
      "           1       0.45      0.15      0.22      3780\n",
      "           2       0.77      0.94      0.85     13050\n",
      "\n",
      "    accuracy                           0.73     19751\n",
      "   macro avg       0.62      0.55      0.55     19751\n",
      "weighted avg       0.69      0.73      0.69     19751\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train, y_train)\n",
    "print(\"Logistic Regression Test Results:\")\n",
    "print(classification_report(y_test, lr.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T17:09:22.977592Z",
     "iopub.status.busy": "2025-04-22T17:09:22.977216Z",
     "iopub.status.idle": "2025-04-22T17:10:14.034303Z",
     "shell.execute_reply": "2025-04-22T17:10:14.033250Z",
     "shell.execute_reply.started": "2025-04-22T17:09:22.977563Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Logistic Regression Test Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.72      0.59      2921\n",
      "           1       0.35      0.49      0.41      3780\n",
      "           2       0.89      0.70      0.78     13050\n",
      "\n",
      "    accuracy                           0.66     19751\n",
      "   macro avg       0.58      0.64      0.59     19751\n",
      "weighted avg       0.73      0.66      0.68     19751\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_balanced = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "lr_balanced.fit(X_train, y_train)\n",
    "print(\"Balanced Logistic Regression Test Results:\")\n",
    "print(classification_report(y_test, lr_balanced.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T17:13:20.963683Z",
     "iopub.status.busy": "2025-04-22T17:13:20.963016Z",
     "iopub.status.idle": "2025-04-22T17:14:57.399488Z",
     "shell.execute_reply": "2025-04-22T17:14:57.398792Z",
     "shell.execute_reply.started": "2025-04-22T17:13:20.963646Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Test Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.31      0.31      2921\n",
      "           1       0.23      0.24      0.24      3780\n",
      "           2       0.73      0.72      0.73     13050\n",
      "\n",
      "    accuracy                           0.57     19751\n",
      "   macro avg       0.42      0.43      0.42     19751\n",
      "weighted avg       0.57      0.57      0.57     19751\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "print(\"Decision Tree Test Results:\")\n",
    "print(classification_report(y_test, dt.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T17:17:24.807357Z",
     "iopub.status.busy": "2025-04-22T17:17:24.807072Z",
     "iopub.status.idle": "2025-04-22T17:18:43.163924Z",
     "shell.execute_reply": "2025-04-22T17:18:43.163161Z",
     "shell.execute_reply.started": "2025-04-22T17:17:24.807337Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Decision Tree Test Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.31      0.30      2921\n",
      "           1       0.24      0.24      0.24      3780\n",
      "           2       0.73      0.72      0.73     13050\n",
      "\n",
      "    accuracy                           0.57     19751\n",
      "   macro avg       0.42      0.42      0.42     19751\n",
      "weighted avg       0.57      0.57      0.57     19751\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt_balanced = DecisionTreeClassifier(random_state=42, class_weight='balanced')\n",
    "dt_balanced.fit(X_train, y_train)\n",
    "print(\"Balanced Decision Tree Test Results:\")\n",
    "print(classification_report(y_test, dt_balanced.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T05:40:59.898952Z",
     "iopub.status.busy": "2025-04-23T05:40:59.897930Z",
     "iopub.status.idle": "2025-04-23T05:41:02.559262Z",
     "shell.execute_reply": "2025-04-23T05:41:02.558109Z",
     "shell.execute_reply.started": "2025-04-23T05:40:59.898918Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X = np.array(df['embedding'].tolist(), dtype=np.float32)  \n",
    "y = df['label_encoded'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T05:41:05.497508Z",
     "iopub.status.busy": "2025-04-23T05:41:05.497184Z",
     "iopub.status.idle": "2025-04-23T05:41:05.613413Z",
     "shell.execute_reply": "2025-04-23T05:41:05.612325Z",
     "shell.execute_reply.started": "2025-04-23T05:41:05.497484Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T05:41:08.923965Z",
     "iopub.status.busy": "2025-04-23T05:41:08.923614Z",
     "iopub.status.idle": "2025-04-23T05:41:14.566768Z",
     "shell.execute_reply": "2025-04-23T05:41:14.565510Z",
     "shell.execute_reply.started": "2025-04-23T05:41:08.923927Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "train_dataset = TensorDataset(torch.tensor(X_train), torch.tensor(y_train))\n",
    "val_dataset = TensorDataset(torch.tensor(X_val), torch.tensor(y_val))\n",
    "test_dataset = TensorDataset(torch.tensor(X_test), torch.tensor(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T17:19:21.726447Z",
     "iopub.status.busy": "2025-04-22T17:19:21.725616Z",
     "iopub.status.idle": "2025-04-22T17:19:21.731971Z",
     "shell.execute_reply": "2025-04-22T17:19:21.731184Z",
     "shell.execute_reply.started": "2025-04-22T17:19:21.726421Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T05:41:28.087477Z",
     "iopub.status.busy": "2025-04-23T05:41:28.087165Z",
     "iopub.status.idle": "2025-04-23T05:41:28.092249Z",
     "shell.execute_reply": "2025-04-23T05:41:28.091033Z",
     "shell.execute_reply.started": "2025-04-23T05:41:28.087456Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "input_size = X_train.shape[1]\n",
    "num_classes = len(le.classes_)\n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "learning_rate = 0.001\n",
    "model = NeuralNetwork(input_size, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T05:41:42.417783Z",
     "iopub.status.busy": "2025-04-23T05:41:42.417360Z",
     "iopub.status.idle": "2025-04-23T05:41:42.423250Z",
     "shell.execute_reply": "2025-04-23T05:41:42.422053Z",
     "shell.execute_reply.started": "2025-04-23T05:41:42.417751Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T17:21:11.723829Z",
     "iopub.status.busy": "2025-04-22T17:21:11.723409Z",
     "iopub.status.idle": "2025-04-22T17:23:23.620159Z",
     "shell.execute_reply": "2025-04-22T17:23:23.619094Z",
     "shell.execute_reply.started": "2025-04-22T17:21:11.723798Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 | Val Accuracy: 0.7221\n",
      "Epoch 2/20 | Val Accuracy: 0.7310\n",
      "Epoch 3/20 | Val Accuracy: 0.7343\n",
      "Epoch 4/20 | Val Accuracy: 0.7363\n",
      "Epoch 5/20 | Val Accuracy: 0.7343\n",
      "Epoch 6/20 | Val Accuracy: 0.7311\n",
      "Epoch 7/20 | Val Accuracy: 0.7321\n",
      "Epoch 8/20 | Val Accuracy: 0.7379\n",
      "Epoch 9/20 | Val Accuracy: 0.7389\n",
      "Epoch 10/20 | Val Accuracy: 0.7422\n",
      "Epoch 11/20 | Val Accuracy: 0.7370\n",
      "Epoch 12/20 | Val Accuracy: 0.7387\n",
      "Epoch 13/20 | Val Accuracy: 0.7405\n",
      "Epoch 14/20 | Val Accuracy: 0.7406\n",
      "Epoch 15/20 | Val Accuracy: 0.7393\n",
      "Epoch 16/20 | Val Accuracy: 0.7415\n",
      "Epoch 17/20 | Val Accuracy: 0.7362\n",
      "Epoch 18/20 | Val Accuracy: 0.7355\n",
      "Epoch 19/20 | Val Accuracy: 0.7404\n",
      "Epoch 20/20 | Val Accuracy: 0.7376\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            val_loss += criterion(outputs, labels).item()\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "    \n",
    "    val_acc = correct / len(val_dataset)\n",
    "    print(f\"Epoch {epoch+1}/{epochs} | Val Accuracy: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T17:25:35.667561Z",
     "iopub.status.busy": "2025-04-22T17:25:35.667208Z",
     "iopub.status.idle": "2025-04-22T17:25:36.065472Z",
     "shell.execute_reply": "2025-04-22T17:25:36.064493Z",
     "shell.execute_reply.started": "2025-04-22T17:25:35.667536Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Neural Network Test Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.55      0.60      2921\n",
      "           1       0.44      0.27      0.34      3780\n",
      "           2       0.80      0.92      0.86     13050\n",
      "\n",
      "    accuracy                           0.74     19751\n",
      "   macro avg       0.63      0.58      0.60     19751\n",
      "weighted avg       0.71      0.74      0.72     19751\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        all_preds.extend(preds.numpy())\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "print(\"\\nNeural Network Test Results:\")\n",
    "print(classification_report(all_labels, all_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T18:08:31.869555Z",
     "iopub.status.busy": "2025-04-22T18:08:31.869256Z",
     "iopub.status.idle": "2025-04-22T18:10:43.054044Z",
     "shell.execute_reply": "2025-04-22T18:10:43.053005Z",
     "shell.execute_reply.started": "2025-04-22T18:08:31.869532Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 | Val Accuracy: 0.6595\n",
      "Epoch 2/20 | Val Accuracy: 0.6788\n",
      "Epoch 3/20 | Val Accuracy: 0.6892\n",
      "Epoch 4/20 | Val Accuracy: 0.6656\n",
      "Epoch 5/20 | Val Accuracy: 0.6452\n",
      "Epoch 6/20 | Val Accuracy: 0.6373\n",
      "Epoch 7/20 | Val Accuracy: 0.6382\n",
      "Epoch 8/20 | Val Accuracy: 0.6346\n",
      "Epoch 9/20 | Val Accuracy: 0.6363\n",
      "Epoch 10/20 | Val Accuracy: 0.6421\n",
      "Epoch 11/20 | Val Accuracy: 0.6382\n",
      "Epoch 12/20 | Val Accuracy: 0.6369\n",
      "Epoch 13/20 | Val Accuracy: 0.6393\n",
      "Epoch 14/20 | Val Accuracy: 0.6413\n",
      "Epoch 15/20 | Val Accuracy: 0.6428\n",
      "Epoch 16/20 | Val Accuracy: 0.6366\n",
      "Epoch 17/20 | Val Accuracy: 0.6408\n",
      "Epoch 18/20 | Val Accuracy: 0.6357\n",
      "Epoch 19/20 | Val Accuracy: 0.6409\n",
      "Epoch 20/20 | Val Accuracy: 0.6392\n"
     ]
    }
   ],
   "source": [
    "class_counts = np.bincount(y_train)\n",
    "class_weights = 1. / class_counts\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float32)\n",
    "criterion_b = nn.CrossEntropyLoss(weight=class_weights)\n",
    "model_balanced = NeuralNetwork(input_size, num_classes)\n",
    "optimizer = optim.Adam(model_balanced.parameters(), lr=0.00001)\n",
    "for epoch in range(epochs):\n",
    "    model_balanced.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_balanced(inputs)\n",
    "        loss = criterion_b(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    \n",
    "    model_balanced.eval()\n",
    "    val_loss = 0\n",
    "    correct_balanced = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = model_balanced(inputs)\n",
    "            val_loss += criterion_b(outputs, labels).item()\n",
    "            preds_balanced = outputs.argmax(dim=1)\n",
    "            correct_balanced += (preds_balanced == labels).sum().item()\n",
    "    \n",
    "    val_acc = correct_balanced / len(val_dataset)\n",
    "    print(f\"Epoch {epoch+1}/{epochs} | Val Accuracy: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T18:12:07.847707Z",
     "iopub.status.busy": "2025-04-22T18:12:07.847321Z",
     "iopub.status.idle": "2025-04-22T18:12:08.282220Z",
     "shell.execute_reply": "2025-04-22T18:12:08.281174Z",
     "shell.execute_reply.started": "2025-04-22T18:12:07.847680Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Neural Network Test Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.72      0.55      2921\n",
      "           1       0.28      0.32      0.30      3780\n",
      "           2       0.87      0.71      0.78     13050\n",
      "\n",
      "    accuracy                           0.64     19751\n",
      "   macro avg       0.53      0.58      0.54     19751\n",
      "weighted avg       0.69      0.64      0.65     19751\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_balanced.eval()\n",
    "all_preds_balanced = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model_balanced(inputs)\n",
    "        preds_balanced = outputs.argmax(dim=1)\n",
    "        all_preds_balanced.extend(preds_balanced.numpy())\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "print(\"\\nNeural Network Test Results:\")\n",
    "print(classification_report(all_labels, all_preds_balanced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T18:31:29.725017Z",
     "iopub.status.busy": "2025-04-22T18:31:29.724029Z",
     "iopub.status.idle": "2025-04-22T18:31:29.735973Z",
     "shell.execute_reply": "2025-04-22T18:31:29.734844Z",
     "shell.execute_reply.started": "2025-04-22T18:31:29.724976Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1) \n",
    "        out, _ = self.lstm(x)\n",
    "        out = out[:, -1, :] \n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "input_size = X_train.shape[1]\n",
    "num_classes = len(le.classes_)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = LSTMModel(input_size=input_size, \n",
    "                 hidden_size=64, \n",
    "                 num_layers=1,  \n",
    "                 output_size=num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T18:33:40.781624Z",
     "iopub.status.busy": "2025-04-22T18:33:40.781245Z",
     "iopub.status.idle": "2025-04-22T18:35:38.180912Z",
     "shell.execute_reply": "2025-04-22T18:35:38.180025Z",
     "shell.execute_reply.started": "2025-04-22T18:33:40.781596Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Val Accuracy: 0.7402\n",
      "Epoch 2/10 | Val Accuracy: 0.7403\n",
      "Epoch 3/10 | Val Accuracy: 0.7411\n",
      "Epoch 4/10 | Val Accuracy: 0.7378\n",
      "Epoch 5/10 | Val Accuracy: 0.7423\n",
      "Epoch 6/10 | Val Accuracy: 0.7395\n",
      "Epoch 7/10 | Val Accuracy: 0.7370\n",
      "Epoch 8/10 | Val Accuracy: 0.7418\n",
      "Epoch 9/10 | Val Accuracy: 0.7424\n",
      "Epoch 10/10 | Val Accuracy: 0.7433\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    val_acc = correct / len(val_dataset)\n",
    "    print(f\"Epoch {epoch+1}/{epochs} | Val Accuracy: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T18:39:45.927447Z",
     "iopub.status.busy": "2025-04-22T18:39:45.927104Z",
     "iopub.status.idle": "2025-04-22T18:39:46.607647Z",
     "shell.execute_reply": "2025-04-22T18:39:46.606676Z",
     "shell.execute_reply.started": "2025-04-22T18:39:45.927421Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Neural Network Test Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.59      0.61      2921\n",
      "           1       0.47      0.22      0.30      3780\n",
      "           2       0.80      0.93      0.86     13050\n",
      "\n",
      "    accuracy                           0.74     19751\n",
      "   macro avg       0.63      0.58      0.59     19751\n",
      "weighted avg       0.71      0.74      0.72     19751\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        all_preds.extend(preds.numpy())\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "print(\"\\nNeural Network Test Results:\")\n",
    "print(classification_report(all_labels, all_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, WeightedRandomSampler\n",
    "import time\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedBiLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout_prob=0.3):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        \n",
    "        self.input_net = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size * 2),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout_prob),\n",
    "            nn.LayerNorm(hidden_size * 2),\n",
    "            \n",
    "            nn.Linear(hidden_size * 2, hidden_size),\n",
    "            nn.Mish()\n",
    "        )\n",
    "        \n",
    "       \n",
    "        self.lstm_layers = nn.ModuleList()\n",
    "        self.lstm_norms = nn.ModuleList()\n",
    "        for i in range(num_layers):\n",
    "            self.lstm_layers.append(nn.LSTM(\n",
    "                hidden_size,\n",
    "                hidden_size // 2,\n",
    "                batch_first=True,\n",
    "                bidirectional=True,\n",
    "                dropout=dropout_prob if i < num_layers - 1 else 0\n",
    "            ))\n",
    "            self.lstm_norms.append(nn.LayerNorm(hidden_size))\n",
    "        \n",
    "\n",
    "        self.attention = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_size,\n",
    "            num_heads=4,\n",
    "            dropout=dropout_prob,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "      \n",
    "        self.temp_conv = nn.Sequential(\n",
    "            nn.Conv1d(hidden_size, hidden_size, kernel_size=3, padding=1, groups=4),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(dropout_prob)\n",
    "        )\n",
    "       \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_size * 2, hidden_size),\n",
    "            nn.LayerNorm(hidden_size),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(dropout_prob),\n",
    "            \n",
    "            nn.Linear(hidden_size, output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.dim() == 1:\n",
    "            x = x.unsqueeze(0)\n",
    "            \n",
    "        x = self.input_net(x)\n",
    "        x = x.unsqueeze(1)\n",
    "        \n",
    "        lstm_out = x\n",
    "        for lstm, norm in zip(self.lstm_layers, self.lstm_norms):\n",
    "            new_out, _ = lstm(lstm_out)\n",
    "            lstm_out = norm(lstm_out + new_out)\n",
    "        \n",
    "        conv_out = self.temp_conv(lstm_out.transpose(1, 2)).transpose(1, 2)\n",
    "        \n",
    "        attn_out, _ = self.attention(conv_out, conv_out, conv_out)\n",
    "        \n",
    "        last_out = attn_out[:, -1, :]\n",
    "        avg_pool = torch.mean(attn_out, dim=1)\n",
    "        combined = torch.cat([last_out, avg_pool], dim=1)\n",
    "        \n",
    "        return self.classifier(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(X_train, num_classes, train_loader, class_weights=None):\n",
    "    device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "    \n",
    "    model_config = {\n",
    "        'input_size': X_train.shape[1],\n",
    "        'hidden_size': 512,\n",
    "        'num_layers': 5,\n",
    "        'output_size': num_classes,\n",
    "        'dropout_prob': 0.01\n",
    "    }\n",
    "    \n",
    "    model = AdvancedBiLSTM(**model_config).to(device)\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=0.0001,\n",
    "        weight_decay=1e-4\n",
    "    )\n",
    "    \n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, \n",
    "        mode='max',\n",
    "        factor=0.5,\n",
    "        patience=2\n",
    "    )\n",
    "    \n",
    "    class_weights = torch.tensor(np.log(class_weights + 1) * 0.5, dtype=torch.float32).to(device)\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    \n",
    "    return device, model, optimizer, criterion, scheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T06:09:07.699728Z",
     "iopub.status.busy": "2025-04-23T06:09:07.699426Z",
     "iopub.status.idle": "2025-04-23T06:12:30.392513Z",
     "shell.execute_reply": "2025-04-23T06:12:30.391489Z",
     "shell.execute_reply.started": "2025-04-23T06:09:07.699709Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_weighted_sampler(y):\n",
    "    class_counts = Counter(y)\n",
    "    num_samples = len(y)\n",
    "    class_weights = {cls: num_samples / count for cls, count in class_counts.items()}\n",
    "    weights = [class_weights[cls] for cls in y]\n",
    "    sampler = WeightedRandomSampler(weights, num_samples, replacement=True)\n",
    "    return sampler\n",
    "\n",
    "def train_model(model, train_loader, val_loader, optimizer, criterion, device, \n",
    "                scheduler=None, epochs=50, clip_value=1.0, patience=5):\n",
    "    best_val_f1 = 0\n",
    "    no_improve = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            with torch.cuda.amp.autocast(enabled=device.type == 'cuda'):\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip_value)\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                \n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "   \n",
    "        val_f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "        \n",
    "        if scheduler:\n",
    "            scheduler.step(val_f1)\n",
    "        \n",
    "        epoch_time = time.time() - start_time\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        print(f'Epoch {epoch+1}/{epochs} | Time: {epoch_time:.2f}s')\n",
    "        print(f'Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}')\n",
    "        print(f'Val F1-score: {val_f1:.4f} | LR: {current_lr:.2e}')\n",
    "        print(classification_report(all_labels, all_preds, digits=4))\n",
    "        print('-' * 60)\n",
    "        \n",
    "        if val_f1 > best_val_f1:\n",
    "            best_val_f1 = val_f1\n",
    "            no_improve = 0\n",
    "            torch.save(model.state_dict(), 'best_model_BiLSTM_Attention.pth')\n",
    "        else:\n",
    "            no_improve += 1\n",
    "            if no_improve >= patience:\n",
    "                print(f'Early stopping at epoch {epoch+1}')\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = create_weighted_sampler(y_train)\n",
    "    \n",
    "train_dataset = TensorDataset(\n",
    "        torch.tensor(X_train, dtype=torch.float32),\n",
    "        torch.tensor(y_train, dtype=torch.long)\n",
    ")\n",
    "val_dataset = TensorDataset(\n",
    "        torch.tensor(X_val, dtype=torch.float32),\n",
    "        torch.tensor(y_val, dtype=torch.long)\n",
    ")\n",
    "test_dataset = TensorDataset(\n",
    "        torch.tensor(X_test, dtype=torch.float32),\n",
    "        torch.tensor(y_test, dtype=torch.long)\n",
    ")\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=batch_size,\n",
    "    sampler=sampler,  \n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=batch_size,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=batch_size,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "\n",
    "class_counts = np.bincount(y_train)\n",
    "class_weights = 1. / class_counts\n",
    "class_weights = class_weights / class_weights.sum() * len(class_counts)\n",
    "\n",
    "device, model, optimizer, criterion, scheduler = initialize_model(\n",
    "    X_train=X_train,\n",
    "    num_classes=len(np.unique(y_train)),\n",
    "    train_loader=train_loader,\n",
    "    class_weights=class_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/var/folders/gg/wqlmrvl91mj28lsltv0ccxqm0000gn/T/ipykernel_10027/4196525237.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=device.type == 'cuda'):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Time: 41.96s\n",
      "Train Loss: 0.0810 | Val Loss: 2.4137\n",
      "Val F1-score: 0.6640 | LR: 1.00e-04\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5597    0.5325    0.5458      3012\n",
      "           1     0.3041    0.4045    0.3472      3713\n",
      "           2     0.8169    0.7492    0.7816     13025\n",
      "\n",
      "    accuracy                         0.6513     19750\n",
      "   macro avg     0.5602    0.5621    0.5582     19750\n",
      "weighted avg     0.6813    0.6513    0.6640     19750\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/var/folders/gg/wqlmrvl91mj28lsltv0ccxqm0000gn/T/ipykernel_10027/4196525237.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=device.type == 'cuda'):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 | Time: 44.88s\n",
      "Train Loss: 0.0752 | Val Loss: 2.4295\n",
      "Val F1-score: 0.6763 | LR: 1.00e-04\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5167    0.6106    0.5597      3012\n",
      "           1     0.3300    0.3555    0.3423      3713\n",
      "           2     0.8258    0.7729    0.7985     13025\n",
      "\n",
      "    accuracy                         0.6697     19750\n",
      "   macro avg     0.5575    0.5797    0.5668     19750\n",
      "weighted avg     0.6854    0.6697    0.6763     19750\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/var/folders/gg/wqlmrvl91mj28lsltv0ccxqm0000gn/T/ipykernel_10027/4196525237.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=device.type == 'cuda'):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 | Time: 44.99s\n",
      "Train Loss: 0.0705 | Val Loss: 2.5964\n",
      "Val F1-score: 0.6785 | LR: 5.00e-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5681    0.5637    0.5659      3012\n",
      "           1     0.3249    0.3684    0.3453      3713\n",
      "           2     0.8147    0.7850    0.7995     13025\n",
      "\n",
      "    accuracy                         0.6729     19750\n",
      "   macro avg     0.5692    0.5724    0.5702     19750\n",
      "weighted avg     0.6850    0.6729    0.6785     19750\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/var/folders/gg/wqlmrvl91mj28lsltv0ccxqm0000gn/T/ipykernel_10027/4196525237.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=device.type == 'cuda'):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 | Time: 44.68s\n",
      "Train Loss: 0.0366 | Val Loss: 3.3145\n",
      "Val F1-score: 0.6911 | LR: 5.00e-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6099    0.5186    0.5606      3012\n",
      "           1     0.3529    0.3310    0.3416      3713\n",
      "           2     0.8006    0.8425    0.8210     13025\n",
      "\n",
      "    accuracy                         0.6969     19750\n",
      "   macro avg     0.5878    0.5640    0.5744     19750\n",
      "weighted avg     0.6873    0.6969    0.6911     19750\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/var/folders/gg/wqlmrvl91mj28lsltv0ccxqm0000gn/T/ipykernel_10027/4196525237.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=device.type == 'cuda'):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 | Time: 44.29s\n",
      "Train Loss: 0.0291 | Val Loss: 3.5222\n",
      "Val F1-score: 0.6843 | LR: 5.00e-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5805    0.5793    0.5799      3012\n",
      "           1     0.3375    0.2545    0.2902      3713\n",
      "           2     0.7937    0.8498    0.8208     13025\n",
      "\n",
      "    accuracy                         0.6966     19750\n",
      "   macro avg     0.5706    0.5612    0.5636     19750\n",
      "weighted avg     0.6755    0.6966    0.6843     19750\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/var/folders/gg/wqlmrvl91mj28lsltv0ccxqm0000gn/T/ipykernel_10027/4196525237.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=device.type == 'cuda'):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 | Time: 44.32s\n",
      "Train Loss: 0.0244 | Val Loss: 3.9198\n",
      "Val F1-score: 0.6923 | LR: 5.00e-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5920    0.5737    0.5827      3012\n",
      "           1     0.3728    0.2440    0.2950      3713\n",
      "           2     0.7912    0.8748    0.8309     13025\n",
      "\n",
      "    accuracy                         0.7103     19750\n",
      "   macro avg     0.5853    0.5642    0.5695     19750\n",
      "weighted avg     0.6822    0.7103    0.6923     19750\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/var/folders/gg/wqlmrvl91mj28lsltv0ccxqm0000gn/T/ipykernel_10027/4196525237.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=device.type == 'cuda'):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 | Time: 43.99s\n",
      "Train Loss: 0.0225 | Val Loss: 3.8706\n",
      "Val F1-score: 0.6848 | LR: 5.00e-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5958    0.5339    0.5631      3012\n",
      "           1     0.3478    0.3046    0.3248      3713\n",
      "           2     0.7927    0.8398    0.8155     13025\n",
      "\n",
      "    accuracy                         0.6925     19750\n",
      "   macro avg     0.5787    0.5594    0.5678     19750\n",
      "weighted avg     0.6790    0.6925    0.6848     19750\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/var/folders/gg/wqlmrvl91mj28lsltv0ccxqm0000gn/T/ipykernel_10027/4196525237.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=device.type == 'cuda'):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 | Time: 44.47s\n",
      "Train Loss: 0.0207 | Val Loss: 4.3865\n",
      "Val F1-score: 0.6848 | LR: 5.00e-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5866    0.5478    0.5665      3012\n",
      "           1     0.3595    0.2494    0.2945      3713\n",
      "           2     0.7852    0.8657    0.8235     13025\n",
      "\n",
      "    accuracy                         0.7014     19750\n",
      "   macro avg     0.5771    0.5543    0.5615     19750\n",
      "weighted avg     0.6749    0.7014    0.6848     19750\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/var/folders/gg/wqlmrvl91mj28lsltv0ccxqm0000gn/T/ipykernel_10027/4196525237.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=device.type == 'cuda'):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 | Time: 43.72s\n",
      "Train Loss: 0.0191 | Val Loss: 4.3729\n",
      "Val F1-score: 0.6869 | LR: 2.50e-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6061    0.5395    0.5709      3012\n",
      "           1     0.3492    0.3113    0.3292      3713\n",
      "           2     0.7940    0.8387    0.8157     13025\n",
      "\n",
      "    accuracy                         0.6939     19750\n",
      "   macro avg     0.5831    0.5632    0.5719     19750\n",
      "weighted avg     0.6817    0.6939    0.6869     19750\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/var/folders/gg/wqlmrvl91mj28lsltv0ccxqm0000gn/T/ipykernel_10027/4196525237.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=device.type == 'cuda'):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 | Time: 33.94s\n",
      "Train Loss: 0.0104 | Val Loss: 4.7945\n",
      "Val F1-score: 0.6861 | LR: 2.50e-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6127    0.5226    0.5641      3012\n",
      "           1     0.3628    0.2507    0.2965      3713\n",
      "           2     0.7805    0.8758    0.8254     13025\n",
      "\n",
      "    accuracy                         0.7044     19750\n",
      "   macro avg     0.5853    0.5497    0.5620     19750\n",
      "weighted avg     0.6764    0.7044    0.6861     19750\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    device=device,\n",
    "    scheduler=scheduler,\n",
    "    epochs=10,\n",
    "    clip_value=0.5,\n",
    "    patience=5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/diana/Documents/GitHub/Hates-speech-detection/notebooks\n"
     ]
    }
   ],
   "source": [
    "%cd Documents/GitHub/Hates-speech-detection/notebooks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Test Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5688    0.5745    0.5716      2921\n",
      "           1     0.3710    0.2476    0.2970      3780\n",
      "           2     0.7991    0.8743    0.8350     13050\n",
      "\n",
      "    accuracy                         0.7100     19751\n",
      "   macro avg     0.5796    0.5654    0.5679     19751\n",
      "weighted avg     0.6831    0.7100    0.6931     19751\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('best_model_BiLSTM_Attention.pth', map_location=device))\n",
    "model.eval()\n",
    "    \n",
    "all_preds = []\n",
    "all_labels = []\n",
    "    \n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "print(\"\\nFinal Test Results:\")\n",
    "print(classification_report(all_labels, all_preds, digits=4))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7223218,
     "sourceId": 11517724,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
